MLPro-GT-DG - Dynamic Games
---------------------------

Here is a concise series designed to practically introduce all users to MLPro-GT-DG, whether you are new to it or an experienced MLPro user.

No experience with MLPro? To learn more about MLPro, please refer to the :ref:`Getting Started page of MLPro <target_mlpro_getstarted>`.

By following the step-by-step guidelines below, we expect you to gain a practical understanding of MLPro-GT and begin using MLPro-GT-DG.

**1. What are Game Theory and Dynamic Games?**
   Game Theory is a field of mathematics that studies strategic interactions where the outcome for each participant depends on the choices of all involved.
   It models situations where individuals or entities make decisions to maximize their own payoffs, considering the potential responses of others.
   Dynamic Games extend this concept to situations where decisions are made sequentially over time, with each playerâ€™s strategy evolving based on previous actions and outcomes.
   These games often involve strategies that adapt as the game progresses, reflecting changing conditions and information.
   The study of dynamic games helps understand complex interactions in fields like economics, politics, and biology, where decisions are interdependent and evolve over time.
   
   For a deeper understanding, we recommend reading the book by Dario Bauso, titled: `Game Theory with Engineering Applications <https://dl.acm.org/doi/10.5555/2948750>`_.

**2. What is MLPro-GT?**
   We assume you have a basic understanding of MLPro and game theory.
   Therefore, you should familiarize yourself with the overview of MLPro-GT by following these steps:

   (a) :ref:`MLPro-GT introduction page <target_overview_GT>`

   (b) `Section 5 of MLPro 1.0 paper <https://doi.org/10.1016/j.mlwa.2022.100341>`_

**3. Understanding Game Board and Player in MLPro-GT-DG**
   Firstly, it is important to understand the structure of a game board in MLPro-GT, which can be found on :ref:`this page <target_gb_gt>`.

   MLPro-GT focuses on multi-player game theory, as game theory offers no significant advantages for single-player scenarios.
   To understand the concept of a player in MLPro-GT, you can visit :ref:`this page <target_players_GT>`.

   Next, you can refer to our how-to files and a sample application that demonstrate how to run and train multi-player scenarios with their own policies, as outlined below:

   (a) :ref:`Howto GT-001: Run Multi-Player with Own Policy <Howto GT 001>`

   (b) :ref:`Howto GT-002: Train Multi-Player <Howto GT 002>`

   (c) `Section 6.2 of MLPro 1.0 paper <https://doi.org/10.1016/j.mlwa.2022.100341>`_

**4. Additional Guidance**
   After completing the previous steps, we hope you will be able to practice with MLPro-GT and begin using this subpackage for your game theory-related activities.
   For more advanced features, we strongly recommend reviewing the following how-to files:

   (a) `Howto RL-HT-001: Hyperparameter Tuning using Hyperopt <https://mlpro-int-hyperopt.readthedocs.io/en/latest/content/01_examples_pool/howto.rl.ht.001.html>`_

   (b) `Howto RL-HT-001: Hyperparameter Tuning using Optuna <https://mlpro-int-optuna.readthedocs.io/en/latest/content/01_examples_pool/howto.rl.ht.002.html>`_

   (c) `Howto RL-ATT-001: Train and Reload Single Agent using Stagnation Detection (Gymnasium) <https://mlpro-int-sb3.readthedocs.io/en/latest/content/01_example_pool/03_howtos_att/howto_rl_att_001_train_and_reload_single_agent_gym_sd.html>`_
