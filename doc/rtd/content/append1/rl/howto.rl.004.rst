`Howto 04 - (RL) Run multi-agent with own policy in multicartpole environment <https://github.com/fhswf/MLPro/blob/main/examples/rl/Howto%2004%20-%20(RL)%20Run%20multi-agent%20with%20own%20policy%20in%20multicartpole%20environment.py>`_
================
Ver. 1.2.0 (2021-11-15)

This module shows how to run an own multi-agent with the enhanced multi-action environment 
MultiCartPole based on the OpenAI Gym CartPole environment.

Prerequisites
`````````````````

Please install the following packages to run this examples properly:
    - :ref:`MLPro <Installation>`
  ..
    - `NumPy <https://pypi.org/project/numpy/>`_
  ..
    - `Matplotlib <https://pypi.org/project/matplotlib/>`_
  ..
    - `OpenAI Gym <https://pypi.org/project/gym/>`_
  ..
    - `Pytorch <https://pypi.org/project/torch/>`_
  ..
    - `Stable-Baselines3 <https://pypi.org/project/stable-baselines3/>`_
  ..
    - `PettingZoo <https://pypi.org/project/PettingZoo/>`_
  ..
    - `Optuna <https://pypi.org/project/optuna/>`_
  ..
    - `Hyperopt <https://pypi.org/project/hyperopt/>`_
  ..
    - `ROS <http://wiki.ros.org/noetic/Installation>`_
    

Example Code
`````````````````

.. literalinclude:: ../../../../../examples/rl/Howto 04 - (RL) Run multi-agent with own policy in multicartpole environment.py
    :language: python

Results
`````````````````
Descriptions, plots, images, screenshots of expected results.
