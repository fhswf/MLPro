`Howto 05 - (RL) Train multi-agent with own policy on multicartpole environment <https://github.com/fhswf/MLPro/blob/main/examples/rl/Howto%2005%20-%20(RL)%20Train%20multi-agent%20with%20own%20policy%20on%20multicartpole%20environment.py>`_
================
Ver. 1.3.1 (2021-12-07)

This module shows how to train an own multi-agent with the enhanced multi-action environment 
MultiCartPole based on the OpenAI Gym CartPole environment.

Prerequisites
`````````````````

Please install the following packages to run this examples properly:
    - :ref:`MLPro <Installation>`
  ..
    - `NumPy <https://pypi.org/project/numpy/>`_
  ..
    - `Matplotlib <https://pypi.org/project/matplotlib/>`_
  ..
    - `OpenAI Gym <https://pypi.org/project/gym/>`_
  ..
    - `Pytorch <https://pypi.org/project/torch/>`_
  ..
    - `Stable-Baselines3 <https://pypi.org/project/stable-baselines3/>`_
  ..
    - `PettingZoo <https://pypi.org/project/PettingZoo/>`_
  ..
    - `Optuna <https://pypi.org/project/optuna/>`_
  ..
    - `Hyperopt <https://pypi.org/project/hyperopt/>`_
  ..
    - `ROS <http://wiki.ros.org/noetic/Installation>`_
    

Example Code
`````````````````

.. literalinclude:: ../../../../../examples/rl/Howto 05 - (RL) Train multi-agent with own policy on multicartpole environment.py
    :language: python

Results
`````````````````
Descriptions, plots, images, screenshots of expected results.

